# THOR - Travel Order Resolver

SystÃ¨me de traitement du langage naturel pour extraire des commandes de voyage depuis du texte ou de la parole, et trouver des itinÃ©raires de train optimaux.

## ğŸ—ï¸ Architecture

Le projet se concentre actuellement sur le module **Speech-to-Text (STT)** : Conversion audio â†’ texte.

Les modules NLP et Pathfinding seront ajoutÃ©s ultÃ©rieurement.

Voir [ARCHITECTURE.md](ARCHITECTURE.md) pour plus de dÃ©tails.

## ğŸ“¦ Installation

### PrÃ©requis

- Python 3.9+
- pip

### Installation de base

```bash
# Clone le repository
git clone <repo-url>
cd THOR

# CrÃ©e un environnement virtuel
python -m venv venv
source venv/bin/activate  # Sur Windows: venv\Scripts\activate

# Installe les dÃ©pendances de base
pip install -e .

# Installe les dÃ©pendances optionnelles selon vos besoins
pip install -e ".[stt]"      # Pour Speech-to-Text
pip install -e ".[nlp]"       # Pour NLP
pip install -e ".[pathfinding]"  # Pour Pathfinding
pip install -e ".[dev]"       # Pour le dÃ©veloppement
```

### Configuration

1. Copiez `.env.example` vers `.env` :
```bash
cp .env.example .env
```

2. Modifiez `.env` selon vos besoins (chemins, clÃ©s API, etc.)

## ğŸš€ Utilisation

### Speech-to-Text

#### Transcrire un fichier audio
```bash
python -m src.cli.stt transcribe --audio path/to/audio.wav --model whisper
```

#### Ã‰valuer un modÃ¨le
```bash
python -m src.cli.stt evaluate \
    --dataset data/splits/test/test.jsonl \
    --model whisper \
    --config configs/stt/whisper_small.yaml \
    --output-dir results/stt/whisper_test \
    --analyze-errors
```


## ğŸ“Š Structure du projet

```
thor/
  src/
    common/          # Modules communs (types, config, logging, etc.)
    stt/             # Module Speech-to-Text
      models/        # ImplÃ©mentations des modÃ¨les STT
      eval/          # MÃ©triques et Ã©valuation
    cli/             # Interfaces en ligne de commande
  configs/           # Fichiers de configuration YAML
  data/              # DonnÃ©es (raw, processed, splits)
  results/           # RÃ©sultats des expÃ©riences
  tests/             # Tests unitaires
  docs/              # Documentation
```

## ğŸ§ª Tests

```bash
# Lancer tous les tests
pytest

# Tests avec couverture
pytest --cov=src tests/
```

## ğŸ“ Documentation

- **[ğŸ“š Guide complet des commandes](COMMANDES.md)** - Toutes les commandes disponibles
- [Architecture complÃ¨te](ARCHITECTURE.md)
- [Documentation STT](src/stt/README.md)
- [Documentation NLP](src/nlp/README.md)
- [Documentation Pipeline](src/pipeline/README.md)

## ğŸ”§ DÃ©veloppement

### Ajouter un nouveau modÃ¨le STT

1. CrÃ©ez un fichier dans `src/stt/models/` (ex: `my_model.py`)
2. ImplÃ©mentez l'interface `STTModel` :
```python
from src.stt.interfaces import STTModel
from src.common.types import STTResult

class MyModel(STTModel):
    def transcribe(self, audio_path: str) -> STTResult:
        # Votre implÃ©mentation
        return STTResult(text="...")
```

3. CrÃ©ez une configuration dans `configs/stt/my_model.yaml`
4. Ajoutez le modÃ¨le dans `src/cli/stt.py` si nÃ©cessaire

Voir `src/stt/models/dummy.py` pour un exemple minimal.

### Workflow de test

```bash
# Test STT
python -m src.cli.stt evaluate \
    --model whisper \
    --dataset data/splits/test/test.jsonl \
    --output-dir results/stt/whisper_test
```

## ğŸ“ˆ MÃ©triques

Le module STT expose des mÃ©triques standardisÃ©es :

- **WER** (Word Error Rate) : Taux d'erreur de mots
- **CER** (Character Error Rate) : Taux d'erreur de caractÃ¨res
- **Latency** : Temps de traitement
- **Real-time Factor (RTF)** : Ratio temps traitement / durÃ©e audio

Les rÃ©sultats sont sauvegardÃ©s dans `results/runs/<timestamp>_stt_<model>/`

## ğŸ¤ Contribution

1. CrÃ©ez une branche pour votre fonctionnalitÃ©
2. Ajoutez des tests
3. Assurez-vous que tous les tests passent
4. CrÃ©ez une pull request

## ğŸ“„ Licence

MIT

## ğŸ‘¥ Auteurs

THOR Team

