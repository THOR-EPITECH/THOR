# üìö Documentation des Commandes THOR

Guide complet de toutes les commandes disponibles dans le projet THOR.

---

## üìã Table des mati√®res

1. [Commandes STT (Speech-to-Text)](#commandes-stt)
2. [Commandes NLP (Natural Language Processing)](#commandes-nlp)
3. [Commandes Pipeline](#commandes-pipeline)
4. [Scripts utilitaires](#scripts-utilitaires)
5. [Configuration](#configuration)

---

## üé§ Commandes STT

### Transcrire un fichier audio

Transcrit un fichier audio en texte.

```bash
python -m src.cli.stt transcribe \
    --audio <chemin_vers_audio> \
    [--model <mod√®le>] \
    [--config <fichier_config>]
```

**Param√®tres :**
- `--audio` (requis) : Chemin vers le fichier audio (.wav, .mp3)
- `--model` (optionnel) : Mod√®le STT √† utiliser (`whisper`, `dummy`) - d√©faut: `whisper`
- `--config` (optionnel) : Chemin vers un fichier de configuration YAML

**Exemples :**
```bash
# Transcription simple avec Whisper
python -m src.cli.stt transcribe --audio data/raw/audio/sample_000001.wav

# Avec configuration personnalis√©e
python -m src.cli.stt transcribe \
    --audio data/raw/audio/sample_000001.wav \
    --model whisper \
    --config configs/stt/whisper_small.yaml
```

**Sortie :**
```
Text: Je voudrais bien aller √† Paris.
Processing time: 2.34s
Confidence: 0.95
```

---

### √âvaluer un mod√®le STT

√âvalue un mod√®le STT sur un dataset de test.

```bash
python -m src.cli.stt evaluate \
    --dataset <chemin_dataset> \
    [--model <mod√®le>] \
    [--config <fichier_config>] \
    [--output-dir <dossier_sortie>] \
    [--analyze-errors] \
    [--top-errors <nombre>]
```

**Param√®tres :**
- `--dataset` (requis) : Chemin vers le fichier JSONL du dataset de test
- `--model` (optionnel) : Mod√®le STT √† √©valuer (`whisper`, `dummy`) - d√©faut: `whisper`
- `--config` (optionnel) : Chemin vers un fichier de configuration YAML
- `--output-dir` (optionnel) : Dossier de sortie pour les r√©sultats - d√©faut: `results/stt`
- `--analyze-errors` (optionnel) : Active l'analyse d√©taill√©e des erreurs
- `--top-errors` (optionnel) : Nombre d'erreurs principales √† afficher - d√©faut: `20`

**Exemples :**
```bash
# √âvaluation basique
python -m src.cli.stt evaluate \
    --dataset data/splits/test/test.jsonl \
    --model whisper

# √âvaluation avec analyse d'erreurs
python -m src.cli.stt evaluate \
    --dataset data/splits/test/test.jsonl \
    --model whisper \
    --config configs/stt/whisper_small.yaml \
    --output-dir results/stt/whisper_test \
    --analyze-errors \
    --top-errors 30
```

**Fichiers g√©n√©r√©s :**
- `metrics.json` : M√©triques agr√©g√©es (WER, CER, Latency, RTF)
- `predictions.jsonl` : Toutes les pr√©dictions d√©taill√©es
- `predictions.csv` : M√™me chose en format CSV
- `report.md` : Rapport markdown complet
- `errors_top.csv` : Top erreurs (si `--analyze-errors` activ√©)

---

## üß† Commandes NLP

### Extraire origine/destination depuis un texte

Extrait la ville de d√©part et d'arriv√©e depuis un texte.

```bash
python -m src.cli.nlp extract \
    --text "<texte>" \
    [--model <mod√®le>] \
    [--config <fichier_config>]
```

**Param√®tres :**
- `--text` (requis) : Texte √† analyser
- `--model` (optionnel) : Mod√®le NLP √† utiliser (`spacy`, `dummy`) - d√©faut: `dummy`
- `--config` (optionnel) : Chemin vers un fichier de configuration YAML

**Exemples :**
```bash
# Extraction simple
python -m src.cli.nlp extract \
    --text "Je veux aller √† Paris depuis Lyon"

# Avec mod√®le fine-tun√©
python -m src.cli.nlp extract \
    --text "Je souhaite voyager de Bordeaux √† Toulouse" \
    --model spacy \
    --config configs/nlp/spacy_finetuned.yaml
```

**Sortie :**
```
Origine: Lyon
Destination: Paris
Valide: True
Confidence: 1.00
```

---

### √âvaluer un mod√®le NLP

√âvalue un mod√®le NLP sur un dataset de test.

```bash
python -m src.cli.nlp evaluate \
    --dataset <chemin_dataset> \
    [--model <mod√®le>] \
    [--config <fichier_config>] \
    [--output-dir <dossier_sortie>]
```

**Param√®tres :**
- `--dataset` (requis) : Chemin vers le fichier JSONL du dataset de test
- `--model` (optionnel) : Mod√®le NLP √† √©valuer (`spacy`, `dummy`) - d√©faut: `dummy`
- `--config` (optionnel) : Chemin vers un fichier de configuration YAML
- `--output-dir` (optionnel) : Dossier de sortie pour les r√©sultats - d√©faut: `results/nlp`

**Exemples :**
```bash
# √âvaluation basique
python -m src.cli.nlp evaluate \
    --dataset data/splits/test/test_nlp.jsonl \
    --model spacy

# √âvaluation avec mod√®le fine-tun√©
python -m src.cli.nlp evaluate \
    --dataset data/splits/test/test_nlp.jsonl \
    --model spacy \
    --config configs/nlp/spacy_finetuned.yaml \
    --output-dir results/nlp/spacy_finetuned_test
```

**Fichiers g√©n√©r√©s :**
- `metrics.json` : M√©triques agr√©g√©es (Precision, Recall, F1, Accuracy)
- `predictions.jsonl` : Toutes les pr√©dictions d√©taill√©es
- `predictions.csv` : M√™me chose en format CSV
- `report.md` : Rapport markdown complet

**M√©triques calcul√©es :**
- **Precision, Recall, F1** : Pour l'extraction d'entit√©s
- **Origin Accuracy** : Pr√©cision sur l'origine
- **Destination Accuracy** : Pr√©cision sur la destination
- **Validation Accuracy** : Pr√©cision sur la d√©tection de demandes valides

---

### Entra√Æner (fine-tuner) un mod√®le NLP

Entra√Æne un mod√®le NLP sur un dataset d'entra√Ænement.

```bash
python -m src.cli.nlp train \
    --train-dataset <chemin_train> \
    [--valid-dataset <chemin_valid>] \
    [--model <mod√®le>] \
    [--config <fichier_config>] \
    [--output-dir <dossier_sortie>] \
    [--n-iter <nombre_iterations>] \
    [--dropout <taux_dropout>]
```

**Param√®tres :**
- `--train-dataset` (requis) : Chemin vers le dataset d'entra√Ænement (JSONL)
- `--valid-dataset` (optionnel) : Chemin vers le dataset de validation (JSONL)
- `--model` (optionnel) : Mod√®le NLP √† entra√Æner (`spacy`) - d√©faut: `spacy`
- `--config` (optionnel) : Chemin vers un fichier de configuration YAML
- `--output-dir` (optionnel) : Dossier o√π sauvegarder le mod√®le entra√Æn√© - d√©faut: `models/nlp`
- `--n-iter` (optionnel) : Nombre d'it√©rations d'entra√Ænement - d√©faut: `20`
- `--dropout` (optionnel) : Taux de dropout - d√©faut: `0.1`

**Exemples :**
```bash
# Entra√Ænement basique
python -m src.cli.nlp train \
    --train-dataset data/splits/train/train_nlp.jsonl \
    --model spacy

# Entra√Ænement complet avec validation
python -m src.cli.nlp train \
    --train-dataset data/splits/train/train_nlp.jsonl \
    --valid-dataset data/splits/valid/valid_nlp.jsonl \
    --model spacy \
    --n-iter 30 \
    --dropout 0.2 \
    --output-dir models/nlp/spacy_finetuned
```

**Sortie :**
```
‚úÖ Training complete!
Model saved to: models/nlp/spacy_finetuned/model

To use this fine-tuned model, update your config:
  custom_model_path: models/nlp/spacy_finetuned/model
```

**Utilisation du mod√®le fine-tun√© :**
Cr√©ez un fichier `configs/nlp/spacy_finetuned.yaml` :
```yaml
nlp:
  model_name: fr_core_news_md
  custom_model_path: models/nlp/spacy_finetuned/model
```

---

## üîÑ Commandes Pipeline

### Traiter un fichier audio complet (STT ‚Üí NLP)

Traite un fichier audio complet : transcription puis extraction origine/destination.

```bash
python -m src.cli.pipeline \
    --audio <chemin_audio> \
    [--stt-model <mod√®le_stt>] \
    [--nlp-model <mod√®le_nlp>] \
    [--config <fichier_config>] \
    [--output <chemin_sortie>]
```

**Param√®tres :**
- `--audio` (requis) : Chemin vers le fichier audio
- `--stt-model` (optionnel) : Mod√®le STT √† utiliser (`whisper`, `vosk`) - d√©faut: `whisper`
- `--nlp-model` (optionnel) : Mod√®le NLP √† utiliser (`spacy`) - d√©faut: `spacy`
- `--config` (optionnel) : Chemin vers un fichier de configuration YAML
- `--output` (optionnel) : Chemin pour sauvegarder les r√©sultats JSON (sinon g√©n√©r√© automatiquement)

**Exemples :**
```bash
# Pipeline basique
python -m src.cli.pipeline \
    --audio data/raw/audio/sample_000160.wav

# Pipeline avec mod√®les sp√©cifiques
python -m src.cli.pipeline \
    --audio data/raw/audio/sample_000160.wav \
    --stt-model whisper \
    --nlp-model spacy \
    --config configs/nlp/spacy_finetuned.yaml

# Pipeline avec sortie personnalis√©e
python -m src.cli.pipeline \
    --audio data/raw/audio/sample_000160.wav \
    --output results/pipeline/mon_resultat.json
```

**Sortie :**
```
=== R√©sultats ===
Transcription: Je veux voyager de Toulouse √† Bordeaux.
Origine: Toulouse
Destination: Bordeaux
Valide: True
Confidence: 1.00

R√©sultats JSON sauvegard√©s dans: results/pipeline/sample_000160_result.json
Rapport markdown g√©n√©r√©: results/pipeline/sample_000160_result.md
```

**Messages d'erreur possibles :**
- `‚ö†Ô∏è Attention : La ville de d√©part est manquante. Veuillez pr√©ciser d'o√π vous partez.`
- `‚ö†Ô∏è Attention : La ville d'arriv√©e est manquante. Veuillez pr√©ciser votre destination.`
- `‚ùå Erreur : Aucune ville d√©tect√©e. Veuillez pr√©ciser une ville de d√©part et/ou d'arriv√©e.`

**Fichiers g√©n√©r√©s :**
- `{audio_name}_result.json` : R√©sultats au format JSON
- `{audio_name}_result.md` : Rapport markdown d√©taill√©

---

## üõ†Ô∏è Scripts utilitaires

### G√©n√©rer un dataset STT

G√©n√®re un dataset STT avec diverses phrases et variations.

```bash
PYTHONPATH=. python3 scripts/generate_stt_dataset.py \
    [--output-dir <dossier_sortie>] \
    [--num-samples <nombre>] \
    [--audio-dir <dossier_audio>] \
    [--seed <graine>]
```

**Param√®tres :**
- `--output-dir` (optionnel) : Dossier de sortie - d√©faut: `data/splits`
- `--num-samples` (optionnel) : Nombre d'√©chantillons √† g√©n√©rer - d√©faut: `1000`
- `--audio-dir` (optionnel) : Dossier pour les fichiers audio - d√©faut: `data/raw/audio`
- `--seed` (optionnel) : Graine al√©atoire pour reproductibilit√© - d√©faut: `42`

**Exemple :**
```bash
PYTHONPATH=. python3 scripts/generate_stt_dataset.py \
    --num-samples 500 \
    --output-dir data/splits
```

---

### G√©n√©rer un dataset NLP

G√©n√®re un dataset NLP massif avec nombreuses variations de phrases.

```bash
PYTHONPATH=. python3 scripts/generate_nlp_dataset.py \
    [--output-dir <dossier_sortie>] \
    [--num-samples <nombre>] \
    [--seed <graine>]
```

**Param√®tres :**
- `--output-dir` (optionnel) : Dossier de sortie - d√©faut: `data/splits`
- `--num-samples` (optionnel) : Nombre d'√©chantillons √† g√©n√©rer - d√©faut: `10000`
- `--seed` (optionnel) : Graine al√©atoire pour reproductibilit√© - d√©faut: `42`

**Exemple :**
```bash
PYTHONPATH=. python3 scripts/generate_nlp_dataset.py \
    --num-samples 5000 \
    --output-dir data/splits
```

**Fichiers g√©n√©r√©s :**
- `train/train_nlp.jsonl` : Dataset d'entra√Ænement
- `valid/valid_nlp.jsonl` : Dataset de validation
- `test/test_nlp.jsonl` : Dataset de test
- `full_nlp_dataset.jsonl` : Dataset complet

---

### G√©n√©rer des fichiers audio

G√©n√®re des fichiers audio √† partir d'un dataset JSONL en utilisant TTS.

```bash
PYTHONPATH=. python3 scripts/generate_audio.py \
    --dataset <chemin_dataset> \
    [--audio-dir <dossier_audio>] \
    [--tts-engine <moteur>] \
    [--no-skip-existing]
```

**Param√®tres :**
- `--dataset` (requis) : Chemin vers le fichier JSONL du dataset
- `--audio-dir` (optionnel) : Dossier de sortie pour les fichiers audio - d√©faut: `data/raw/audio`
- `--tts-engine` (optionnel) : Moteur TTS √† utiliser (`gtts`, `pyttsx3`) - d√©faut: `gtts`
- `--no-skip-existing` (optionnel) : Ne pas ignorer les fichiers existants

**Exemple :**
```bash
PYTHONPATH=. python3 scripts/generate_audio.py \
    --dataset data/splits/full_dataset.jsonl \
    --audio-dir data/raw/audio \
    --tts-engine gtts
```

---

### Pr√©parer des splits train/test/valid

Divise un dataset complet en splits train/test/valid.

```bash
PYTHONPATH=. python3 scripts/prepare_splits.py \
    --input <fichier_entr√©e> \
    --output <dossier_sortie> \
    [--train-ratio <ratio>] \
    [--valid-ratio <ratio>] \
    [--test-ratio <ratio>] \
    [--no-shuffle] \
    [--seed <graine>]
```

**Param√®tres :**
- `--input` (requis) : Fichier JSONL d'entr√©e
- `--output` (requis) : Dossier de sortie
- `--train-ratio` (optionnel) : Ratio pour train - d√©faut: `0.7`
- `--valid-ratio` (optionnel) : Ratio pour validation - d√©faut: `0.15`
- `--test-ratio` (optionnel) : Ratio pour test - d√©faut: `0.15`
- `--no-shuffle` (optionnel) : Ne pas m√©langer les donn√©es
- `--seed` (optionnel) : Graine al√©atoire - d√©faut: `42`

**Exemple :**
```bash
PYTHONPATH=. python3 scripts/prepare_splits.py \
    --input data/splits/full_dataset.jsonl \
    --output data/splits \
    --train-ratio 0.7 \
    --valid-ratio 0.15 \
    --test-ratio 0.15
```

---

### Tester le pipeline sur plusieurs exemples

Teste le pipeline sur plusieurs fichiers audio ou textes.

```bash
PYTHONPATH=. python3 scripts/test_pipeline_examples.py \
    [--audio-dir <dossier_audio>] \
    [--audio-files <fichier1> <fichier2> ...] \
    [--texts <texte1> <texte2> ...] \
    [--dataset <chemin_dataset>] \
    [--config <fichier_config>] \
    [--output <fichier_sortie>] \
    [--num-samples <nombre>]
```

**Param√®tres :**
- `--audio-dir` (optionnel) : Dossier contenant des fichiers audio √† tester
- `--audio-files` (optionnel) : Liste de fichiers audio √† tester
- `--texts` (optionnel) : Liste de textes √† tester
- `--dataset` (optionnel) : Fichier JSONL avec phrases √† tester
- `--config` (optionnel) : Fichier de configuration
- `--output` (optionnel) : Fichier JSON de sortie pour les r√©sultats
- `--num-samples` (optionnel) : Nombre d'√©chantillons depuis le dataset - d√©faut: `10`

**Exemples :**
```bash
# Tester sur plusieurs textes
PYTHONPATH=. python3 scripts/test_pipeline_examples.py \
    --texts "Je veux aller √† Paris" "Je souhaite voyager de Lyon √† Marseille" \
    --config configs/nlp/spacy_finetuned.yaml

# Tester sur plusieurs fichiers audio
PYTHONPATH=. python3 scripts/test_pipeline_examples.py \
    --audio-files data/raw/audio/sample_000001.wav data/raw/audio/sample_000002.wav \
    --config configs/nlp/spacy_finetuned.yaml

# Tester sur un dataset
PYTHONPATH=. python3 scripts/test_pipeline_examples.py \
    --dataset data/splits/test/test_nlp.jsonl \
    --num-samples 20 \
    --config configs/nlp/spacy_finetuned.yaml \
    --output results/pipeline_test.json
```

---

### Nettoyer le projet

Supprime les fichiers inutiles (__pycache__, fichiers temporaires, etc.).

```bash
PYTHONPATH=. python3 scripts/clean_project.py
```

**Supprime :**
- Tous les dossiers `__pycache__`
- Fichiers temporaires (`.pyc`, `.py~`, `.DS_Store`)
- Dossiers vides
- Fichiers de test individuels (garde les rapports)

---

## ‚öôÔ∏è Configuration

### Fichiers de configuration

Les fichiers de configuration sont au format YAML et se trouvent dans `configs/`.

**Structure :**
```
configs/
  base.yaml              # Configuration de base
  stt/
    whisper_small.yaml   # Configuration Whisper
  nlp/
    spacy_finetuned.yaml # Configuration spaCy fine-tun√©
  pipeline/
    full.yaml            # Configuration pipeline complet
```

**Exemple de configuration NLP fine-tun√©e :**
```yaml
nlp:
  model_name: fr_core_news_md
  custom_model_path: models/nlp/spacy_finetuned/model
```

**Exemple de configuration STT :**
```yaml
stt:
  model_size: small
  language: fr
  device: cpu
```

---

## üìù Variables d'environnement

Vous pouvez utiliser `PYTHONPATH=.` avant les commandes pour s'assurer que les modules sont trouv√©s :

```bash
PYTHONPATH=. python3 -m src.cli.stt transcribe --audio audio.wav
```

Ou d√©finir dans votre shell :
```bash
export PYTHONPATH=.
```

---

## üîç Format des datasets

### Dataset STT (JSONL)

Chaque ligne contient :
```json
{
  "id": "sample_001",
  "audio_path": "data/raw/audio/sample_001.wav",
  "transcript": "Je veux aller √† Paris depuis Lyon"
}
```

### Dataset NLP (JSONL)

Chaque ligne contient :
```json
{
  "id": "nlp_000001",
  "sentence": "Je veux aller √† Paris depuis Lyon",
  "origin": "Lyon",
  "destination": "Paris",
  "is_valid": true
}
```

---

## üìä R√©sultats g√©n√©r√©s

### Structure des r√©sultats

```
results/
  stt/
    <model>_test/
      metrics.json          # M√©triques agr√©g√©es
      predictions.jsonl     # Pr√©dictions d√©taill√©es
      predictions.csv       # Format CSV
      report.md             # Rapport markdown
      errors_top.csv        # Top erreurs (si analyse activ√©e)
  
  nlp/
    <model>_test/
      metrics.json          # M√©triques agr√©g√©es
      predictions.jsonl     # Pr√©dictions d√©taill√©es
      predictions.csv       # Format CSV
      report.md             # Rapport markdown
  
  pipeline/
    <audio_name>_result.json  # R√©sultats JSON
    <audio_name>_result.md     # Rapport markdown
```

---

## üöÄ Exemples de workflows complets

### Workflow 1 : √âvaluer un mod√®le STT

```bash
# 1. G√©n√©rer le dataset
PYTHONPATH=. python3 scripts/generate_stt_dataset.py --num-samples 500

# 2. √âvaluer le mod√®le
python -m src.cli.stt evaluate \
    --dataset data/splits/test/test.jsonl \
    --model whisper \
    --config configs/stt/whisper_small.yaml \
    --output-dir results/stt/whisper_test \
    --analyze-errors
```

### Workflow 2 : Entra√Æner et √©valuer un mod√®le NLP

```bash
# 1. G√©n√©rer le dataset NLP
PYTHONPATH=. python3 scripts/generate_nlp_dataset.py --num-samples 5000

# 2. Entra√Æner le mod√®le
python -m src.cli.nlp train \
    --train-dataset data/splits/train/train_nlp.jsonl \
    --valid-dataset data/splits/valid/valid_nlp.jsonl \
    --model spacy \
    --n-iter 30 \
    --output-dir models/nlp/spacy_finetuned

# 3. √âvaluer le mod√®le fine-tun√©
python -m src.cli.nlp evaluate \
    --dataset data/splits/test/test_nlp.jsonl \
    --model spacy \
    --config configs/nlp/spacy_finetuned.yaml \
    --output-dir results/nlp/spacy_finetuned_test
```

### Workflow 3 : Pipeline complet

```bash
# Traiter un fichier audio complet
python -m src.cli.pipeline \
    --audio data/raw/audio/sample_000160.wav \
    --stt-model whisper \
    --nlp-model spacy \
    --config configs/nlp/spacy_finetuned.yaml
```

---

## üí° Conseils

1. **Utilisez toujours `PYTHONPATH=.`** avec les scripts Python
2. **Les rapports markdown** sont g√©n√©r√©s automatiquement apr√®s chaque √©valuation
3. **Les mod√®les fine-tun√©s** doivent √™tre configur√©s dans un fichier YAML
4. **Les messages d'erreur** indiquent clairement les villes manquantes
5. **La confiance** varie de 0.0 √† 1.0 selon la qualit√© de l'extraction

---

## üìû Aide

Pour obtenir l'aide d'une commande :
```bash
python -m src.cli.stt --help
python -m src.cli.nlp --help
python -m src.cli.pipeline --help
```

Pour obtenir l'aide d'une sous-commande :
```bash
python -m src.cli.stt transcribe --help
python -m src.cli.nlp train --help
```

---

**Derni√®re mise √† jour :** 2026-01-09

