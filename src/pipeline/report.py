"""
GÃ©nÃ©ration de rapports markdown pour les rÃ©sultats du pipeline.
"""
from pathlib import Path
from typing import Dict, Any
from datetime import datetime


def generate_pipeline_report(result: Dict[str, Any], output_path: str | Path, stt_model_name: str = None, nlp_model_name: str = None, pathfinding_model_name: str = None) -> Path:
    """
    GÃ©nÃ¨re un rapport markdown pour un rÃ©sultat de pipeline.
    
    Args:
        result: RÃ©sultat du pipeline
        output_path: Chemin oÃ¹ sauvegarder le rapport
    
    Returns:
        Chemin du fichier crÃ©Ã©
    """
    output_path = Path(output_path)
    output_path.parent.mkdir(parents=True, exist_ok=True)
    
    audio_path = result.get("audio_path", "N/A")
    transcript = result.get("transcript", "")
    origin = result.get("origin")
    destination = result.get("destination")
    is_valid = result.get("is_valid", False)
    confidence = result.get("confidence")
    error_message = result.get("error_message")
    
    stt_metadata = result.get("stt_metadata", {})
    nlp_metadata = result.get("nlp_metadata", {})
    
    # RÃ©cupÃ¨re les noms des modÃ¨les
    stt_model = stt_model_name or stt_metadata.get('model', 'N/A')
    nlp_model = nlp_model_name or nlp_metadata.get('model', 'N/A')
    pathfinding_model = pathfinding_model_name or "Non utilisÃ©"
    
    route = result.get("route")
    
    # Formate les valeurs
    confidence_str = f"{confidence:.2f}" if confidence is not None else "N/A"
    processing_time = stt_metadata.get('processing_time')
    processing_time_str = f"{processing_time:.2f}s" if processing_time else "N/A"
    
    # GÃ©nÃ¨re le rapport
    report = f"""# Rapport Pipeline - Traitement Audio

**Date**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}  
**Fichier audio**: {audio_path}

## ğŸ”§ Configuration

- **ModÃ¨le STT**: {stt_model}
- **ModÃ¨le NLP**: {nlp_model}
- **ModÃ¨le Pathfinding**: {pathfinding_model}

---

## ğŸ“ Transcription (STT)

```
{transcript}
```

### MÃ©tadonnÃ©es STT
- **ModÃ¨le**: {stt_model}
- **Langue dÃ©tectÃ©e**: {stt_metadata.get('detected_language', stt_metadata.get('language', 'N/A'))}
- **Segments**: {stt_metadata.get('segments', 'N/A')}
- **Temps de traitement**: {processing_time_str}

---

## ğŸ¯ Extraction NLP

### RÃ©sultats
- **Origine**: {origin if origin else "Non dÃ©tectÃ©e"}
- **Destination**: {destination if destination else "Non dÃ©tectÃ©e"}
- **Demande valide**: {"âœ… Oui" if is_valid else "âŒ Non"}
- **Confiance**: {confidence_str}
"""
    
    # Ajoute le message d'erreur si prÃ©sent
    if error_message:
        report += f"""
### âš ï¸ Message d'erreur
{error_message}
"""
    
    report += f"""
### MÃ©tadonnÃ©es NLP
- **ModÃ¨le**: {nlp_model}
- **MÃ©thode d'extraction**: {nlp_metadata.get('extraction_method', 'N/A')}
- **Lieux dÃ©tectÃ©s**: {', '.join(nlp_metadata.get('locations_found', [])) if nlp_metadata.get('locations_found') else 'Aucun'}

---
"""
    
    # Section Pathfinding
    if route:
        if route.get('steps'):
            total_time = route.get('total_time', 0)
            hours = int(total_time // 60) if total_time else 0
            minutes = int(total_time % 60) if total_time else 0
            time_str = f"{hours}h{minutes:02d} ({total_time:.0f} min)" if total_time else "N/A"
            
            report += f"""
## ğŸ—ºï¸ ItinÃ©raire (Pathfinding)

### RÃ©sultats
- **â±ï¸ Temps de trajet**: {time_str}
- **ğŸ“ Distance totale**: {route['total_distance']:.1f} km
- **ğŸ›¤ï¸ Nombre d'Ã©tapes**: {len(route['steps'])}
"""
            
            # DÃ©tails des segments si disponibles
            segments = route.get('metadata', {}).get('segments', [])
            if segments:
                report += """
### ğŸ“Š DÃ©tails du trajet

| # | Type | DÃ©part | ArrivÃ©e | Temps | Distance | Trains/jour |
|---|------|--------|---------|-------|----------|-------------|
"""
                for i, seg in enumerate(segments, 1):
                    train_type = seg.get('type_train', 'Autre')
                    if train_type == 'TGV':
                        type_emoji = 'ğŸš„ TGV'
                    elif train_type == 'OUIGO':
                        type_emoji = 'ğŸŸ¢ OUIGO'
                    elif train_type == 'IntercitÃ©s':
                        type_emoji = 'ğŸšƒ IntercitÃ©s'
                    elif train_type == 'TER':
                        type_emoji = 'ğŸšˆ TER'
                    else:
                        type_emoji = f'ğŸš‚ {train_type}'
                    
                    temps = seg.get('temps_min', 0)
                    distance = seg.get('distance_km', 0)
                    nb_trains = seg.get('nb_trains_jour', 0)
                    
                    report += f"| {i} | {type_emoji} | {seg['from']} | {seg['to']} | {temps:.0f} min | {distance:.1f} km | {nb_trains} |\n"
                
                # RÃ©sumÃ© par type de train
                train_types = {}
                for seg in segments:
                    t = seg.get('type_train', 'Autre')
                    train_types[t] = train_types.get(t, 0) + 1
                
                report += "\n### ğŸš‚ Types de trains utilisÃ©s\n"
                for t, count in sorted(train_types.items(), key=lambda x: -x[1]):
                    if t == 'TGV':
                        report += f"- ğŸš„ **TGV**: {count} segment(s)\n"
                    elif t == 'OUIGO':
                        report += f"- ğŸŸ¢ **OUIGO**: {count} segment(s)\n"
                    elif t == 'IntercitÃ©s':
                        report += f"- ğŸšƒ **IntercitÃ©s**: {count} segment(s)\n"
                    elif t == 'TER':
                        report += f"- ğŸšˆ **TER**: {count} segment(s)\n"
                    else:
                        report += f"- ğŸš‚ **{t}**: {count} segment(s)\n"
            else:
                report += "\n### Ã‰tapes du trajet\n"
                for i, step in enumerate(route['steps'], 1):
                    report += f"{i}. {step}\n"
            
            if route.get('metadata', {}).get('path_uic'):
                report += f"""
### ğŸ”§ DÃ©tails techniques
- **Mode**: {route['metadata'].get('mode', 'N/A')}
- **UIC dÃ©part**: {route['metadata'].get('origin_uic', 'N/A')}
- **UIC arrivÃ©e**: {route['metadata'].get('destination_uic', 'N/A')}
- **Nombre de gares**: {route['metadata'].get('num_stations', 'N/A')}
"""
        elif route.get('metadata', {}).get('error'):
            report += f"""
## ğŸ—ºï¸ ItinÃ©raire (Pathfinding)

âš ï¸ **Erreur**: {route['metadata']['error']}
"""
        else:
            report += """
## ğŸ—ºï¸ ItinÃ©raire (Pathfinding)

âŒ **Aucun itinÃ©raire trouvÃ©**
"""
    
    report += """
---

## ğŸ“Š Analyse

"""
    
    # Analyse de la qualitÃ©
    if origin and destination:
        report += "âœ… **Extraction complÃ¨te** : Origine et destination dÃ©tectÃ©es\n\n"
    elif origin:
        report += "âš ï¸ **Origine seulement** : Destination manquante\n\n"
    elif destination:
        report += "âš ï¸ **Destination seulement** : Origine manquante\n\n"
    else:
        report += "âŒ **Aucune extraction** : Origine et destination non dÃ©tectÃ©es\n\n"
    
    if is_valid:
        report += "âœ… La demande est **valide** (demande de trajet dÃ©tectÃ©e)\n\n"
    else:
        report += "âŒ La demande est **invalide** (pas une demande de trajet)\n\n"
    
    # DÃ©tails de l'extraction
    report += """---

## ğŸ” DÃ©tails techniques

### Pipeline utilisÃ©
1. **STT** : Transcription audio â†’ texte
2. **NLP** : Extraction origine/destination depuis le texte"""
    
    if pathfinding_model_name:
        report += """
3. **Pathfinding** : Recherche d'itinÃ©raire entre origine et destination"""
    
    report += """

### EntitÃ©s dÃ©tectÃ©es
"""
    
    entities = nlp_metadata.get('entities', [])
    if entities:
        for entity in entities:
            report += f"- {entity.get('text', 'N/A')} ({entity.get('label', 'N/A')})\n"
    else:
        report += "- Aucune entitÃ© dÃ©tectÃ©e\n"
    
    report += f"""

---

## ğŸ“ Fichiers

- **Audio source**: `{audio_path}`
- **Rapport gÃ©nÃ©rÃ©**: `{output_path.name}`

---

## ğŸ“ Notes

Ce rapport a Ã©tÃ© gÃ©nÃ©rÃ© automatiquement par le pipeline THOR.

Pour relancer le traitement avec les mÃªmes modÃ¨les :
```bash
python3 -m src.cli.pipeline --audio {audio_path} --stt-model {stt_model} --nlp-model {nlp_model}"""
    
    if pathfinding_model_name:
        report += f" --pathfinding-model {pathfinding_model_name}"
    
    report += """
```
"""
    
    # Sauvegarde
    with open(output_path, 'w', encoding='utf-8') as f:
        f.write(report)
    
    return output_path

