# Benchmark NLP - Comparaison de modÃ¨les

**Date**: 2026-01-09 16:24:32  
**Dataset**: data/splits/test/test_nlp.jsonl  
**Nombre de modÃ¨les**: 5

---

## ğŸ“Š RÃ©sultats comparatifs

### Tableau rÃ©capitulatif

| ModÃ¨le | F1-Score | Precision | Recall | Origin Acc. | Dest. Acc. | Valid Acc. | Status |
|--------|----------|-----------|--------|-------------|------------|-------------|--------|
| spacy (spacy_finetuned) ğŸ† | 0.6214 | 0.6221 | 0.6210 | 0.9498 | 0.8390 | 1.0000 | âœ… |
| regex_advanced  | 0.4298 | 0.5097 | 0.3898 | 0.8082 | 0.2957 | 0.8596 | âœ… |
| spacy  | 0.4066 | 0.4070 | 0.4132 | 0.7260 | 0.4224 | 1.0000 | âœ… |
| dummy  | 0.2302 | 0.2751 | 0.2078 | 0.7991 | 0.5708 | 0.6381 | âœ… |
| transformers | âŒ Erreur | - | - | - | - | - | âŒ |

---

## ğŸ“ˆ DÃ©tails par modÃ¨le

### spacy (spacy_finetuned)

#### MÃ©triques principales

- **F1-Score**: 0.6214 Â± 0.4845
- **Precision**: 0.6221 Â± 0.4849
- **Recall**: 0.6210 Â± 0.4845

#### PrÃ©cision par entitÃ©

- **Origine**: 0.9498 Â± 0.2184
- **Destination**: 0.8390 Â± 0.3675
- **Les deux correctes**: 0.8368 Â± 0.3696

#### Validation

- **PrÃ©cision de validation**: 1.0000 Â± 0.0000

#### Configuration

```yaml
{
  "model_name": "fr_core_news_md",
  "custom_model_path": "models/nlp/spacy_finetuned/model"
}
```

ğŸ“„ [Rapport dÃ©taillÃ©](./spacy (spacy_finetuned)/report.md)

---

### regex_advanced

#### MÃ©triques principales

- **F1-Score**: 0.4298 Â± 0.4330
- **Precision**: 0.5097 Â± 0.4956
- **Recall**: 0.3898 Â± 0.4167

#### PrÃ©cision par entitÃ©

- **Origine**: 0.8082 Â± 0.3937
- **Destination**: 0.2957 Â± 0.4563
- **Les deux correctes**: 0.2705 Â± 0.4442

#### Validation

- **PrÃ©cision de validation**: 0.8596 Â± 0.3474

ğŸ“„ [Rapport dÃ©taillÃ©](./regex_advanced/report.md)

---

### spacy

#### MÃ©triques principales

- **F1-Score**: 0.4066 Â± 0.4686
- **Precision**: 0.4070 Â± 0.4714
- **Recall**: 0.4132 Â± 0.4759

#### PrÃ©cision par entitÃ©

- **Origine**: 0.7260 Â± 0.4460
- **Destination**: 0.4224 Â± 0.4939
- **Les deux correctes**: 0.4075 Â± 0.4914

#### Validation

- **PrÃ©cision de validation**: 1.0000 Â± 0.0000

ğŸ“„ [Rapport dÃ©taillÃ©](./spacy/report.md)

---

### dummy

#### MÃ©triques principales

- **F1-Score**: 0.2302 Â± 0.3717
- **Precision**: 0.2751 Â± 0.4362
- **Recall**: 0.2078 Â± 0.3490

#### PrÃ©cision par entitÃ©

- **Origine**: 0.7991 Â± 0.4007
- **Destination**: 0.5708 Â± 0.4950
- **Les deux correctes**: 0.5000 Â± 0.5000

#### Validation

- **PrÃ©cision de validation**: 0.6381 Â± 0.4805

ğŸ“„ [Rapport dÃ©taillÃ©](./dummy/report.md)

---

### âŒ transformers

**Erreur**: 'NoneType' object has no attribute 'endswith'

## ğŸ” Analyse comparative

### ğŸ† Meilleur modÃ¨le: **spacy (spacy_finetuned)**

- **F1-Score**: 0.6214

### Comparaison

- **regex_advanced** vs **spacy (spacy_finetuned)**: -0.1916 (-30.8%)
- **spacy** vs **spacy (spacy_finetuned)**: -0.2148 (-34.6%)
- **dummy** vs **spacy (spacy_finetuned)**: -0.3912 (-63.0%)

---

## ğŸ“ Fichiers gÃ©nÃ©rÃ©s

- `comparison.json`: RÃ©sultats comparatifs au format JSON
- `benchmark_report.md`: Ce rapport
- `<model_name>/`: Dossiers individuels avec rÃ©sultats dÃ©taillÃ©s (si `save_individual_results=True`)

---

## ğŸ“ Notes

Ce benchmark compare les modÃ¨les NLP sur le mÃªme dataset pour une Ã©valuation Ã©quitable.

Pour plus de dÃ©tails sur un modÃ¨le spÃ©cifique, consultez son rapport individuel dans son dossier.
